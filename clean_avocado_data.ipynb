{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a1d9a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360234aa",
   "metadata": {},
   "source": [
    "## Limpieza y Preprocesamiento de Datos de Aguacate\n",
    "\n",
    "Este cuaderno contiene los pasos seguidos para limpiar y preparar los datos de aguacate para su posterior análisis y uso en modelos de machine learning.\n",
    "\n",
    "### 1. Cargar y manejar los valores nulos\n",
    "\n",
    "El primer paso consiste en cargar el conjunto de datos y manejar los valores nulos. Para ello, se utilizan las librerías de `pandas` para cargar el archivo CSV y luego se manejan los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e9b806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos a processar:\n",
      "Unnamed: 0      0\n",
      "Date            0\n",
      "AveragePrice    0\n",
      "Total Volume    0\n",
      "4046            0\n",
      "4225            0\n",
      "4770            0\n",
      "Total Bags      0\n",
      "Small Bags      0\n",
      "Large Bags      0\n",
      "XLarge Bags     0\n",
      "type            0\n",
      "year            0\n",
      "region          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "avocado_data = pd.read_csv(\"./data/avocado.csv\")\n",
    "\n",
    "print('Valores nulos a processar:')\n",
    "print(avocado_data.isnull().sum())\n",
    "\n",
    "num_cols = avocado_data.select_dtypes(include='number').columns\n",
    "avocado_data[num_cols] = avocado_data[num_cols].fillna(avocado_data[num_cols].mean())\n",
    "\n",
    "cat_cols = avocado_data.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    avocado_data[col] = avocado_data[col].fillna(avocado_data[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5420bf",
   "metadata": {},
   "source": [
    "#### Explicación:\n",
    "- Se cargan los datos desde el archivo CSV.\n",
    "- Para las columnas numéricas, se sustituyen los valores nulos por la media de cada columna. Esto es una estrategia común cuando se trata con valores nulos en variables numéricas, ya que ayuda a mantener la distribución general de los datos.\n",
    "- Para las columnas categóricas, se sustituyen los valores nulos por el valor más frecuente (moda) de cada columna. Esto es útil cuando se tienen variables como categorías, donde reemplazar valores nulos por el valor más común es una opción válida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b69cd1",
   "metadata": {},
   "source": [
    "### 2. Eliminar columnas innecesarias\n",
    "A continuación, se elimina una columna que no aporta información relevante al análisis o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e10f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avocado_data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129fe701",
   "metadata": {},
   "source": [
    "#### Explicación:\n",
    "Se elimina la columna 'Unnamed: 0' porque  no contiene información útil para el análisis o los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5fc17",
   "metadata": {},
   "source": [
    "### 3. Detección y tratamiento de valores atípicos\n",
    "El siguiente paso es detectar y tratar los valores atípicos. Para esto, se utiliza el método de Rango Intercuartílico (IQR) para identificar los valores que se encuentran fuera de los límites establecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5b2e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_outliers = ['AveragePrice', 'Total Volume', '4046', '4225', '4770']\n",
    "for col in cols_outliers:\n",
    "    Q1 = avocado_data[col].quantile(0.25)\n",
    "    Q3 = avocado_data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    avocado_data = avocado_data[(avocado_data[col] >= lower) & (avocado_data[col] <= upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc39e0b",
   "metadata": {},
   "source": [
    "#### Explicación:\n",
    "\n",
    "- Se seleccionan las columnas numéricas relevantes que pueden contener valores atípicos.\n",
    "- Para cada columna, se calculan los valores de los cuartiles (Q1 y Q3) y el Rango Intercuartílico (IQR). Los valores atípicos se identifican como aquellos que se encuentran fuera de los límites lower y upper (1.5 veces el IQR por debajo de Q1 y por encima de Q3).\n",
    "- Luego, se filtra el conjunto de datos para eliminar las filas que contienen valores fuera de estos límites. Esto ayuda a mejorar la calidad de los datos y la precisión de los modelos al reducir la influencia de los valores extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3a112",
   "metadata": {},
   "source": [
    "### 4. Conversión de variables categóricas a variables dummy\n",
    "Después, se convierten las variables categóricas, como type y region, en variables numéricas utilizando One-Hot Encoding. Este proceso crea una nueva columna binaria para cada categoría dentro de una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "373660d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avocado_data = pd.get_dummies(avocado_data, columns=['type', 'region'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90111e29",
   "metadata": {},
   "source": [
    "#### Explicación:\n",
    "- Se utiliza la función pd.get_dummies para convertir las columnas categóricas type y region en columnas binarias. Cada categoría se convierte en una columna separada, donde un valor de 1 indica que la fila pertenece a esa categoría, y un valor de 0 indica que no.\n",
    "- El parámetro drop_first=True se utiliza para evitar la multicolinealidad, es decir, se elimina una de las columnas generadas para cada variable categórica, ya que esta puede ser inferida a partir de las otras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052f02f",
   "metadata": {},
   "source": [
    "### 5. Estandarización de datos\n",
    "En este paso, se estandarizan las características numéricas del conjunto de datos. La estandarización es crucial para los modelos de machine learning, ya que garantiza que todas las variables tengan la misma escala y ninguna domine sobre las demás debido a diferencias de magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02ccc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = ['AveragePrice', 'Total Volume', '4046', '4225', '4770', \n",
    "                 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags']\n",
    "\n",
    "avocado_data[cols_to_scale] = scaler.fit_transform(avocado_data[cols_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d8f90",
   "metadata": {},
   "source": [
    "#### Explicación:\n",
    "- Se utiliza el StandardScaler de la librería sklearn para estandarizar las columnas numéricas seleccionadas. Este transformador asegura que todas las variables tengan media 0 y desviación estándar 1.\n",
    "- La estandarización es fundamental cuando se usan modelos que son sensibles a las escalas de las variables, como los modelos basados en distancia (p. ej., KNN, SVM) o los que utilizan gradientes (p. ej., regresión logística, redes neuronales)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358599b7",
   "metadata": {},
   "source": [
    "### 6. Guardar los datos limpios\n",
    "Finalmente, se guarda el conjunto de datos limpio en un nuevo archivo CSV para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e13848",
   "metadata": {},
   "outputs": [],
   "source": [
    "avocado_data.to_csv(\"./data/avocado_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05c9cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  AveragePrice  Total Volume      4046      4225      4770  \\\n",
      "0  2015-12-27     -0.678662      0.208861 -0.402076  1.549884 -0.234086   \n",
      "1  2015-12-20     -0.621101      0.078051 -0.416538  1.158791 -0.185652   \n",
      "2  2015-12-13     -1.829879      0.963330 -0.411733  3.729048  0.158050   \n",
      "3  2015-12-06     -1.398173      0.415083 -0.398275  2.247982 -0.117788   \n",
      "4  2015-11-29     -0.822564      0.024420 -0.405877  1.126900 -0.102548   \n",
      "\n",
      "   Total Bags  Small Bags  Large Bags  XLarge Bags  ...  region_Seattle  \\\n",
      "0   -0.384125   -0.277729   -0.363378    -0.144263  ...           False   \n",
      "1   -0.361659   -0.248597   -0.363123    -0.144263  ...           False   \n",
      "2   -0.399445   -0.298060   -0.362782    -0.144263  ...           False   \n",
      "3   -0.464288   -0.383700   -0.360937    -0.144263  ...           False   \n",
      "4   -0.453932   -0.372515   -0.357084    -0.144263  ...           False   \n",
      "\n",
      "   region_SouthCarolina  region_SouthCentral  region_Southeast  \\\n",
      "0                 False                False             False   \n",
      "1                 False                False             False   \n",
      "2                 False                False             False   \n",
      "3                 False                False             False   \n",
      "4                 False                False             False   \n",
      "\n",
      "   region_Spokane  region_StLouis  region_Syracuse  region_Tampa  region_West  \\\n",
      "0           False           False            False         False        False   \n",
      "1           False           False            False         False        False   \n",
      "2           False           False            False         False        False   \n",
      "3           False           False            False         False        False   \n",
      "4           False           False            False         False        False   \n",
      "\n",
      "   region_WestTexNewMexico  \n",
      "0                    False  \n",
      "1                    False  \n",
      "2                    False  \n",
      "3                    False  \n",
      "4                    False  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "print(avocado_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
